# üßë‚Äçüíª Individual Project - SoulCode Academy

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![Google Cloud](https://img.shields.io/badge/Google%20Cloud-Platform-red)](https://cloud.google.com/)
[![MongoDB](https://img.shields.io/badge/MongoDB-Atlas-green)](https://www.mongodb.com/cloud/atlas)
[![PySpark](https://img.shields.io/badge/PySpark-Data%20Processing-orange)](https://spark.apache.org/docs/latest/api/python/)
[![SparkSQL](https://img.shields.io/badge/SparkSQL-Query-yellow)](https://spark.apache.org/docs/latest/sql-programming-guide.html)

## üìÑ Project Overview

This project, developed as part of the **SoulCode Academy** curriculum, involves comprehensive data engineering and analysis tasks. The primary focus is on utilizing **Python**, **Google Cloud Platform (GCP)**, **MongoDB Atlas**, **PySpark**, and **SparkSQL** to process, analyze, and store data efficiently.

---

## üéØ Objectives

- **Infrastructure Level:**
  - Store the dataset in a cloud environment (**Google Cloud Storage**).
  - Save both the original and processed files in **MongoDB Atlas** in separate collections.
  - Ensure DataFrames are saved in a **Google Cloud Storage** bucket.

- **Pandas Level:**
  - Translate data from its original language to **Portuguese-BR**.
  - Extract data accurately into a DataFrame.
  - Identify and clean inconsistent data, handling **NaN** or **NA** values appropriately.
  - Drop unnecessary columns with explanations for their removal.
  - Provide comments for each step to ensure clarity.

- **PySpark Level:**
  - Define the DataFrame structure using **StructType**.
  - Identify and clean inconsistent or null data.
  - Drop unnecessary columns or rows with explanations.
  - Rename at least two columns.
  - Create at least two new columns with relevant information derived from existing columns (using aggregation, grouping, or joins).
  - Apply filters, sorting, and grouping to extract business-relevant data.
  - Utilize at least two **Window Functions**.

- **SparkSQL Level:**
  - Perform a minimum of five different queries using **SparkSQL**, with explanations for the choice of functions and the purpose of each query.

---

## üõ† Technologies Utilized

- **Programming Language:**
  - ![Python](https://img.shields.io/badge/-Python-3776AB?logo=python&logoColor=white)

- **Cloud Platforms:**
  - ![Google Cloud Platform](https://img.shields.io/badge/-GCP-4285F4?logo=google-cloud&logoColor=white)
  - ![MongoDB Atlas](https://img.shields.io/badge/-MongoDB%20Atlas-47A248?logo=mongodb&logoColor=white)

- **Data Processing:**
  - ![Pandas](https://img.shields.io/badge/-Pandas-150458?logo=pandas&logoColor=white)
  - ![PySpark](https://img.shields.io/badge/-PySpark-E25A1C?logo=apache-spark&logoColor=white)
  - ![SparkSQL](https://img.shields.io/badge/-SparkSQL-FFCA28?logo=apache-spark&logoColor=black)

---

## üìÇ Repository Structure

```bash
üì¶ Python-Projeto-Individual-SoulCode-Engenharia-e-Analise
 ‚î£ üìú Atividade_Individual_-_SoulCode_-_Renan_Marques_Rodrigues.ipynb  # Jupyter Notebook with analysis and code
 ‚îó üìú README.md                                                        # Project documentation
```

---

## üöÄ Getting Started

1. **Clone the Repository:**
   ```bash
   git clone https://github.com/RenanBjj/Python-Projeto-Individual-SoulCode-Engenharia-e-Analise.git
   cd Python-Projeto-Individual-SoulCode-Engenharia-e-Analise
   ```

2. **Set Up the Environment:**
   - Ensure you have **Python 3.8** or higher installed.
   - Install the required packages:
     ```bash
     pip install pandas pyspark pymongo google-cloud-storage
     ```

3. **Configure Cloud Services:**
   - Set up a **Google Cloud Storage** bucket and update the notebook with your credentials.
   - Create a **MongoDB Atlas** cluster and obtain the connection string.

4. **Run the Notebook:**
   - Open `Atividade_Individual_-_SoulCode_-_Renan_Marques_Rodrigues.ipynb` in **Jupyter Notebook** or **JupyterLab**.
   - Execute the cells sequentially to perform data processing and analysis tasks.

---

## üìä Analysis Highlights

- **Data Translation:** Successfully translated dataset content to **Portuguese-BR**.
- **Data Cleaning:** Identified and handled inconsistent data, ensuring a clean dataset.
- **Feature Engineering:** Created new features to enhance data analysis.
- **Advanced Queries:** Executed complex queries using **SparkSQL** to extract meaningful insights.

---

## üì¨ Contact

For questions or collaborations:

- **GitHub:** [RenanBjj](https://github.com/RenanBjj)
- **LinkedIn:** [Renan Marques Rodrigues](https://www.linkedin.com/in/renan-marques-rodrigues/)
- **Email:** [renan.marques@example.com](mailto:renan.marques@example.com)

---

Developed with a focus on practical application of data engineering and analysis techniques.
